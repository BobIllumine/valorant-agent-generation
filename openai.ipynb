{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-04-28T10:01:39.423641Z",
     "end_time": "2023-04-28T10:01:39.433265Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from time import sleep\n",
    "\n",
    "from transformers import GPT2TokenizerFast\n",
    "import numpy as np\n",
    "import openai\n",
    "import pandas as pd\n",
    "import fandom\n",
    "import nltk\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "openai.api_key = \"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\"\n",
    "COMPLETION_MODEL = 'text-davinci-003'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-28T07:59:06.417155Z",
     "end_time": "2023-04-28T07:59:06.422731Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "os.makedirs(os.path.join('.', 'valorant_wiki'), exist_ok=True)\n",
    "wiki_path = os.path.join('.', 'valorant_wiki')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-28T07:59:07.431333Z",
     "end_time": "2023-04-28T07:59:07.433995Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "fandom.set_wiki(\"valorant\")\n",
    "\n",
    "agents_list = ['Astra', 'Breach', 'Brimstone', 'Chamber', 'Cypher', 'Fade', 'Gekko', 'Harbor', 'Jett', 'KAYO', 'Killjoy', 'Neon', 'Omen', 'Phoenix', 'Raze', 'Reyna', 'Sage', 'Skye', 'Sova', 'Viper', 'Yoru']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-28T07:59:08.407883Z",
     "end_time": "2023-04-28T07:59:08.412620Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "outputs": [],
   "source": [
    "def retrieve_agent_page(name: str, output_dir: str):\n",
    "    assert name in agents_list\n",
    "    page = fandom.page(name)\n",
    "    os.makedirs(os.path.join(output_dir, f'{page.title}'), exist_ok=True)\n",
    "    agent_path = os.path.join(output_dir, page.title)\n",
    "    needed_sections = ['Biography', 'Personality', 'Appearance', 'Abilities', 'Relations']\n",
    "    ability_map = {\n",
    "        'C': '',\n",
    "        'Q': '',\n",
    "        'E': '',\n",
    "        'X': ''\n",
    "    }\n",
    "    for key in ability_map.keys():\n",
    "        ability_map[key] = re.findall(f'{key} – (.+)\\n', page.section('Abilities'))[0]\n",
    "    raw_list = []\n",
    "    for sec in needed_sections:\n",
    "        if page.section(sec) is None:\n",
    "            continue\n",
    "        fc = re.sub(r'(https?:\\/\\/(?:www\\.|(?!www)))[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b([-a-zA-Z0-9()@:%_\\+.~#?&//=]*)', '', page.section(sec))\n",
    "        lines = fc.splitlines()\n",
    "        if sec == 'Biography':\n",
    "            lines = lines[4:]\n",
    "            fc = '\\n'.join(lines)\n",
    "            fc = re.sub(r'[^\\n]*Early life.*', '', fc, flags=re.IGNORECASE | re.DOTALL)\n",
    "        sc = re.sub(r'\\[.+\\]', '', fc)\n",
    "        tc = sc.removeprefix(f'{sec}\\n')\n",
    "\n",
    "        raw_list.append([name, sec, tc, len(word_tokenize(tc))])\n",
    "\n",
    "    df = pd.DataFrame(raw_list, columns=['title', 'heading', 'content', 'tokens'])\n",
    "    df.set_index(['title', 'heading'])\n",
    "\n",
    "    # with open(os.path.join(agent_path, f'abilities.txt'), 'w') as f:\n",
    "    #     for value in ability_map.values():\n",
    "    #         f.write(page.title + '\\n')\n",
    "    #         new_page = fandom.page(value)\n",
    "    #         f.write(f'{new_page.section(\"Description\")}')\n",
    "    df.to_csv(\n",
    "        os.path.join(agent_path, f'{name}.csv'),\n",
    "        header=True,\n",
    "        index=False\n",
    "    )\n",
    "    return df\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-28T10:11:32.794604Z",
     "end_time": "2023-04-28T10:11:32.799639Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "outputs": [
    {
     "data": {
      "text/plain": "   title      heading                                            content  \\\n0  Astra    Biography  Hailing from Accra, Ghana, Efia Danso is a Rad...   \n1  Astra  Personality  “\\n \"You can tell a person's character by thei...   \n2  Astra   Appearance  Astra is of Ghanaian descent and has a dark sk...   \n3  Astra    Abilities  \\nPassive\\nX – Astral Form\\nACTIVATE to enter ...   \n4  Astra    Relations  Astra has been observing many of VALORANT's ag...   \n\n   tokens  \n0     449  \n1     123  \n2     161  \n3     307  \n4     110  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>heading</th>\n      <th>content</th>\n      <th>tokens</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Astra</td>\n      <td>Biography</td>\n      <td>Hailing from Accra, Ghana, Efia Danso is a Rad...</td>\n      <td>449</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Astra</td>\n      <td>Personality</td>\n      <td>“\\n \"You can tell a person's character by thei...</td>\n      <td>123</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Astra</td>\n      <td>Appearance</td>\n      <td>Astra is of Ghanaian descent and has a dark sk...</td>\n      <td>161</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Astra</td>\n      <td>Abilities</td>\n      <td>\\nPassive\\nX – Astral Form\\nACTIVATE to enter ...</td>\n      <td>307</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Astra</td>\n      <td>Relations</td>\n      <td>Astra has been observing many of VALORANT's ag...</td>\n      <td>110</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_dfs = []\n",
    "for agent in agents_list:\n",
    "    agent_dfs.append(retrieve_agent_page(agent, os.path.join(wiki_path, 'agents')))\n",
    "complete = pd.concat(agent_dfs, axis=0)\n",
    "complete.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-28T10:11:33.951130Z",
     "end_time": "2023-04-28T10:12:02.377911Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "outputs": [],
   "source": [
    "complete.to_csv(os.path.join(wiki_path, 'agents', 'full.csv'), index=False, header=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-28T10:12:02.377996Z",
     "end_time": "2023-04-28T10:12:02.378157Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "outputs": [],
   "source": [
    "EMBEDDING_MODEL = 'curie'\n",
    "\n",
    "DOC_EMBEDDING_MODEL = f'text-search-{EMBEDDING_MODEL}-doc-001'\n",
    "QUERY_EMBEDDING_MODEL = f'text-search-{EMBEDDING_MODEL}-query-001'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-28T10:12:02.378073Z",
     "end_time": "2023-04-28T10:12:02.378275Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "outputs": [],
   "source": [
    "def get_embedding(text: str, model: str) -> list[float]:\n",
    "    sleep(1)\n",
    "    result = openai.Embedding.create(\n",
    "        model=model,\n",
    "        input=text)\n",
    "    return result[\"data\"][0][\"embedding\"]\n",
    "\n",
    "def get_doc_embedding(text: str) -> list[float]:\n",
    "    return get_embedding(text, DOC_EMBEDDING_MODEL)\n",
    "\n",
    "def get_query_embedding(text: str) -> list[float]:\n",
    "    return get_embedding(text, QUERY_EMBEDDING_MODEL)\n",
    "\n",
    "def compute_doc_embeddings(df: pd.DataFrame) -> dict[tuple[str, str], list[float]]:\n",
    "    \"\"\"\n",
    "    Create an embedding for each row in the dataframe using the OpenAI Embeddings API.\n",
    "\n",
    "    Return a dictionary that maps between each embedding vector and the index of the row that it corresponds to.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        idx: get_doc_embedding(r.content.replace(\"\\n\", \" \")) for idx, r in df.iterrows()\n",
    "    }"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-28T10:12:02.378107Z",
     "end_time": "2023-04-28T10:12:02.378340Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "outputs": [],
   "source": [
    "def load_embeddings(fname: str) -> dict[tuple[str, str], list[float]]:\n",
    "    \"\"\"\n",
    "    Read the document embeddings and their keys from a CSV.\n",
    "\n",
    "    fname is the path to a CSV with exactly these named columns:\n",
    "        \"title\", \"heading\", \"0\", \"1\", ... up to the length of the embedding vectors.\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_csv(fname, header=0)\n",
    "    max_dim = max([int(c) for c in df.columns if c != \"title\" and c != \"heading\"])\n",
    "    return {\n",
    "        (r.title, r.heading): [r[str(i)] for i in range(max_dim + 1)] for _, r in df.iterrows()\n",
    "    }"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-28T10:12:02.378143Z",
     "end_time": "2023-04-28T10:12:02.378393Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "outputs": [],
   "source": [
    "context_embeddings = compute_doc_embeddings(complete)\n",
    "with open('embeddings.txt', 'w') as f:\n",
    "    f.write(str(context_embeddings))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-28T10:12:02.378222Z",
     "end_time": "2023-04-28T10:14:21.022968Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "outputs": [],
   "source": [
    "def vector_similarity(x: list[float], y: list[float]) -> float:\n",
    "    \"\"\"\n",
    "    We could use cosine similarity or dot product to calculate the similarity between vectors.\n",
    "    In practice, we have found it makes little difference.\n",
    "    \"\"\"\n",
    "    return np.dot(np.array(x), np.array(y))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-28T10:14:21.069777Z",
     "end_time": "2023-04-28T10:14:21.070058Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "outputs": [],
   "source": [
    "def order_document_sections_by_query_similarity(query: str, contexts: dict[tuple[str, str], np.array]) -> list[tuple[float, tuple[str, str]]]:\n",
    "    \"\"\"\n",
    "    Find the query embedding for the supplied query, and compare it against all of the pre-calculated document embeddings\n",
    "    to find the most relevant sections.\n",
    "\n",
    "    Return the list of document sections, sorted by relevance in descending order.\n",
    "    \"\"\"\n",
    "    query_embedding = get_query_embedding(query)\n",
    "\n",
    "    document_similarities = sorted([\n",
    "        (vector_similarity(query_embedding, doc_embedding), doc_index) for doc_index, doc_embedding in contexts.items()\n",
    "    ], reverse=True)\n",
    "\n",
    "    return document_similarities"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-28T10:14:21.069858Z",
     "end_time": "2023-04-28T10:14:21.070275Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "outputs": [],
   "source": [
    "MAX_SECTION_LEN = 4000\n",
    "SEPARATOR = \"\\n* \"\n",
    "\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n",
    "separator_len = len(tokenizer.tokenize(SEPARATOR))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-28T11:43:07.721986Z",
     "end_time": "2023-04-28T11:43:08.451787Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "outputs": [],
   "source": [
    "def construct_prompt(question: str, context_embeddings: dict, df: pd.DataFrame) -> str:\n",
    "    \"\"\"\n",
    "    Fetch relevant\n",
    "    \"\"\"\n",
    "    most_relevant_document_sections = order_document_sections_by_query_similarity(question, context_embeddings)\n",
    "    print(df)\n",
    "    chosen_sections = []\n",
    "    chosen_sections_len = 0\n",
    "    chosen_sections_indexes = []\n",
    "\n",
    "    for _, section_index in most_relevant_document_sections:\n",
    "        # Add contexts until we run out of space.\n",
    "        document_section = df.iloc[section_index]\n",
    "        chosen_sections_len += document_section.tokens.sum() + separator_len\n",
    "        if chosen_sections_len > MAX_SECTION_LEN:\n",
    "            break\n",
    "\n",
    "        chosen_sections.append(SEPARATOR + document_section.content.replace(\"\\n\", \" \"))\n",
    "        chosen_sections_indexes.append(str(section_index))\n",
    "\n",
    "    # Useful diagnostic information\n",
    "    print(f\"Selected {len(chosen_sections)} document sections:\")\n",
    "    print(\"\\n\".join(chosen_sections_indexes))\n",
    "\n",
    "    header = \"\"\"Answer the question as creatively as possible using the provided context. \\n\\nContext:\\n\"\"\"\n",
    "\n",
    "    return header + \"\".join(chosen_sections) + \"\\n\\n Q: \" + question + \"\\n A:\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-28T11:43:09.002142Z",
     "end_time": "2023-04-28T11:43:09.008484Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'construct_prompt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m prompt \u001B[38;5;241m=\u001B[39m \u001B[43mconstruct_prompt\u001B[49m(\u001B[38;5;124m\"\"\"\u001B[39m\u001B[38;5;124mGenerate a new Valorant sentinel agent. Print name, role, biography, abilities (C, Q, E, X, be creative, but make them fit into Valorant\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124ms meta), appearance, relationships with other agents.\u001B[39m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;124m    \u001B[39m\u001B[38;5;124m\"\"\"\u001B[39m,\n\u001B[1;32m      3\u001B[0m                           context_embeddings,\n\u001B[1;32m      4\u001B[0m                           complete)\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;28mlen\u001B[39m(prompt))\n\u001B[1;32m      6\u001B[0m completion \u001B[38;5;241m=\u001B[39m openai\u001B[38;5;241m.\u001B[39mCompletion\u001B[38;5;241m.\u001B[39mcreate(\n\u001B[1;32m      7\u001B[0m     model\u001B[38;5;241m=\u001B[39mCOMPLETION_MODEL,\n\u001B[1;32m      8\u001B[0m     prompt\u001B[38;5;241m=\u001B[39mprompt,\n\u001B[1;32m      9\u001B[0m     temperature\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.0\u001B[39m,\n\u001B[1;32m     10\u001B[0m     max_tokens\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m800\u001B[39m\n\u001B[1;32m     11\u001B[0m )\n",
      "\u001B[0;31mNameError\u001B[0m: name 'construct_prompt' is not defined"
     ]
    }
   ],
   "source": [
    "prompt = construct_prompt(\"\"\"Generate a new Valorant sentinel agent. Print name, role, biography, abilities (C, Q, E, X, be creative, but make them fit into Valorant's meta), appearance, relationships with other agents.\n",
    "    \"\"\",\n",
    "                          context_embeddings,\n",
    "                          complete)\n",
    "print(len(prompt))\n",
    "completion = openai.Completion.create(\n",
    "    model=COMPLETION_MODEL,\n",
    "    prompt=prompt,\n",
    "    temperature=0.0,\n",
    "    max_tokens=800\n",
    ")\n",
    "print(completion.choices[0].text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-28T11:43:10.548828Z",
     "end_time": "2023-04-28T11:43:44.046260Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
